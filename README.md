# max-whisper: Speech Recognition with MAX Graph

**Modular Hackathon 2025 Submission**

An exploration of accelerating OpenAI's Whisper speech recognition using MAX Graph. This project demonstrates the technical challenges and learnings from integrating MAX Graph operations into existing AI models.

## What I Built

| Component | CPU Version | GPU Version | MAX Graph Version |
|-----------|-------------|-------------|-------------------|
| **Speech Recognition** | ‚úÖ Full transcription | ‚úÖ Full transcription | üîÑ Partial output |
| **Text Output** | ‚úÖ Complete audio analysis | ‚úÖ Complete audio analysis | ‚ö†Ô∏è Single words only |
| **Integration** | ‚úÖ Native implementation | ‚úÖ CUDA acceleration | ‚úÖ Compiles and runs |

**Current progress:** Successfully built working CPU and GPU baselines, plus a MAX Graph encoder that compiles and processes audio but produces limited transcription output. The technical foundation is solid - the challenge lies in the mathematical precision required for complex AI model integration.

## Quick Start

```bash
git clone https://github.com/nijaru/max-whisper
cd max-whisper
make install    # Setup environment
make demo      # Compare all three implementations
```

## What I Built

Three implementations:
- `whisper_cpu.py` - baseline OpenAI Whisper 
- `whisper_gpu.py` - CUDA accelerated version
- `whisper_max.py` - MAX Graph encoder version

## MAX Graph Implementation Details

### Technical Achievements
- **Complete MAX Graph encoder** - 4-layer transformer with real operations
- **Full weight integration** - All 65 pretrained weights from Whisper tiny
- **Successful compilation** - Complex computation graphs compile and execute
- **End-to-end pipeline** - Audio ‚Üí MAX Graph encoder ‚Üí PyTorch decoder

### Current Limitations
- **Transcription quality** - Produces single words instead of full text
- **Feature compatibility** - Encoder output doesn't fully match PyTorch decoder expectations
- **Mathematical precision** - Subtle differences compound across transformer layers

## The Challenge

Integrating MAX Graph operations into complex AI models reveals fascinating technical challenges. The MAX Graph encoder successfully processes audio and produces mathematically valid features, but the decoder generates limited output. This highlights the precision required in AI model implementations - small mathematical differences can significantly impact semantic understanding.

Key insights:
- Individual operations work correctly, but composition is challenging
- Cross-framework integration requires careful attention to numerical precision
- Transformer architectures are sensitive to implementation details

## What I Learned

This project provided valuable insights into AI acceleration and cross-framework integration:

**Technical Discoveries:**
- MAX Graph operations integrate well with existing codebases
- Weight extraction and tensor conversion work smoothly
- Complex computation graphs compile successfully

**Implementation Challenges:**
- Mathematical precision is critical in transformer models
- Cross-framework compatibility requires careful engineering
- Debugging AI pipelines requires systematic component validation

**Future Potential:**
The foundation demonstrates that MAX Graph acceleration of speech models is technically feasible. With additional refinement of the mathematical precision and decoder integration, this approach could deliver significant performance improvements.

## Try It Yourself

```bash
# Setup
make install        # Install dependencies
make env-check      # Verify environment

# Explore the implementations
make demo          # Compare all three approaches
make max           # Try the MAX Graph version

# Compare working versions
make cpu           # Working CPU baseline
make gpu           # Working GPU version
```

## Project Structure

```
‚îú‚îÄ‚îÄ src/model/           
‚îÇ   ‚îú‚îÄ‚îÄ whisper_cpu.py      # ‚úÖ CPU baseline - works
‚îÇ   ‚îú‚îÄ‚îÄ whisper_gpu.py      # ‚úÖ GPU accelerated - works  
‚îÇ   ‚îî‚îÄ‚îÄ whisper_max.py      # üîÑ MAX Graph encoder - partial
‚îú‚îÄ‚îÄ benchmark_all.py     # Performance testing
‚îî‚îÄ‚îÄ audio_samples/       # Test audio
```

Built during the Modular Hackathon 2025 weekend.